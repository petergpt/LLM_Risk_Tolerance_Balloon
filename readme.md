Below is a **README.md** template incorporating your requested changes. It emphasizes usage first, provides instructions for interpreting results, and includes references and acknowledgments to the original BART authors. It also includes the MIT license, co‐author credits (Peter Gostev and o1-pro), and a note that the README was generated by o1-pro.

---

# Balloon Analogue Risk Task (BART) for LLMs

**Co‐authored by**:  
- [Peter Gostev](https://www.linkedin.com/in/peter-gostev/)  
- **o1-pro**  

*(This README was generated by **o1-pro**. MIT License below.)*

## Table of Contents
1. [Introduction](#introduction)  
2. [Usage & Quick Start](#usage--quick-start)  
3. [Interpreting Results](#interpreting-results)  
4. [Repository Structure](#repository-structure)  
5. [Configuration](#configuration)  
6. [Analysis & Output Files](#analysis--output-files)  
7. [Technical Overview](#technical-overview)  
8. [References & Credits](#references--credits)  
9. [License (MIT)](#license-mit)

---

## 1. Introduction

This repository implements a **Balloon Analogue Risk Task (BART)** for large language models (LLMs). The BART was originally developed for **human participants** to measure risk‐taking behavior. Here, we adapt it so that LLMs can “play” the BART, allowing us to observe how they choose to **pump** (to earn more) or **cash out** (to lock in earnings), risking a “burst” that forfeits the balloon’s earnings.

We build on the methodology from:  
> **Lejuez CW, Read JP, Kahler CW, Richards JB, Ramsey SE, Stuart GL, Strong DR, Brown RA.** Evaluation of a behavioral measure of risk taking: the Balloon Analogue Risk Task (BART). *J Exp Psychol Appl.* 2002 Jun;8(2):75-84. doi: [10.1037//1076-898x.8.2.75](https://doi.org/10.1037//1076-898x.8.2.75).

Our code calls various LLMs via the [OpenRouter API](https://openrouter.ai/) and prompts them to decide “Pump” or “Cash Out.”

---

## 2. Usage & Quick Start

1. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```
   *(or use your preferred environment setup).*

2. **Set up `bart_config.yaml`**  
   - Add your *OpenRouter* API key either as an environment variable `OPENROUTER_API_KEY` or directly in the YAML under `openrouter_api_key`.
   - Specify which models to run in `model_list`.
   - E.g.:
     ```yaml
     experiment_name: "LLM_BART_Experiment"
     min_pumps: 1
     max_pumps: 20
     reward_per_pump: 0.1
     num_balloons: 5
     debug_mode: false
     model_list:
       - "anthropic/claude-3.7-sonnet"
       - "openai/gpt-4o-2024-11-20"
       - "openai/gpt-4o-mini"
     ```

3. **Run the experiment**  
   ```bash
   python main.py
   ```
   - The script loads your config, randomly generates thresholds per balloon, and queries each model.

4. **Check logs** (in `logs/` by default)  
   - One combined CSV of all balloon results
   - A summary CSV with average pumps, adjusted pumps, total earnings, etc.

### Behavior with `debug_mode`
- If `debug_mode: true`, you’ll see **full request/response** logs for each query in the console.
- If `debug_mode: false`, you’ll get a concise overview of whether the balloon **bursts** or the model **cashes out**, plus the total pumps and final earnings, without detailed JSON logs.

---

## 3. Interpreting Results

1. **Combined CSV** (`BART_combined_YYYYMMDD-HHMMSS.csv`):
   - Each row = **one balloon** for one model.
   - Columns include:
     - `model`, `balloon_id`  
     - `threshold_pumps` (hidden balloon threshold)  
     - `pumps_attempted` (final number of pumps)  
     - `burst` (True/False)  
     - `earnings` (how much was earned for that balloon)  
     - `choices`, `full_responses` for deeper analysis

2. **Summary CSV** (`BART_summary_YYYYMMDD-HHMMSS.csv`):
   - Each row = **one model** (plus an “ALL” row).
   - Key fields:
     - `avg_pumps`: Mean pumps across that model’s balloons
     - `burst_rate`: Proportion of balloons that burst
     - `avg_earnings`: Mean earnings
     - `adjusted_pumps`: Mean pumps only on balloons that did **not** burst

3. **Adjusted pumps** is especially interesting:  
   - It measures how aggressively the model pumps **once you exclude** any balloons that burst and ended pumps forcibly.

4. **Comparisons**:  
   - Compare average pumps across models to see which ones are more “risk-taking.”  
   - Compare burst rates to see which models push to the threshold more often.

---

## 4. Repository Structure

```
.
├─ bart_experiment.py      # Main BART logic: handles balloon pumping
├─ main.py                 # Entry point: reads config, spawns runs, writes CSV
├─ logger_utils.py         # Utilities for optional JSON/CSV logging
├─ openrouter_api.py       # Simple client for OpenRouter
├─ analyze_results.py      # Script to parse existing logs and produce stats
├─ bart_config.yaml        # (Example config) - list of models & BART parameters
└─ logs/                   # Default output directory (auto-created)
```

---

## 5. Configuration

**`bart_config.yaml`** controls all main parameters:

- `min_pumps`, `max_pumps`  
- `reward_per_pump`  
- `num_balloons`  
- `model_list`: LLMs to be tested  
- `debug_mode`: whether to log full request/response or just simpler output  
- (Optional) `openrouter_api_key`: If you prefer storing your key in config.

---

## 6. Analysis & Output Files

1. **Combined CSV**:  
   - `logs/BART_combined_YYYYMMDD-HHMMSS.csv`  
   - Detailed row-by-row balloon data.

2. **Summary CSV**:  
   - `logs/BART_summary_YYYYMMDD-HHMMSS.csv`  
   - Aggregated stats per model (e.g. `avg_pumps`, `burst_rate`, etc.).

3. **Further analysis** can be done via:
   ```bash
   python analyze_results.py --file logs/BART_combined_...
   ```
   or load the CSV into Python/pandas for custom analysis or plotting.

---

## 7. Technical Overview

- **Single-balloon conversation**  
  Each balloon starts fresh with a system message describing BART. The code logs each user–assistant turn:  
  1. **User** says “Balloon #N, current earnings X. Do you pump or cash out?”  
  2. **Assistant** responds “Pump” or “Cash Out.”  
  3. The code checks if the balloon bursts and either continues or ends.  
- **No cross-balloon memory**  
  We discard the conversation once the balloon ends, so the next balloon is unaffected by prior results.  
- **OpenRouter** is used to query the model. If a 429 or 500 error occurs, the script retries a few times with exponential backoff.

---

## 8. References & Credits

- **Original BART Paper**  
  > Lejuez CW, Read JP, Kahler CW, Richards JB, Ramsey SE, Stuart GL, Strong DR, Brown RA. *Evaluation of a behavioral measure of risk taking: the Balloon Analogue Risk Task (BART)*. J Exp Psychol Appl. 2002 Jun;8(2):75-84. [doi: 10.1037//1076-898x.8.2.75](https://doi.org/10.1037//1076-898x.8.2.75).

- **OpenRouter** ([OpenRouter.ai](https://openrouter.ai/)) for a unified API to multiple LLM providers.

**Co‐authored by**:  
- [Peter Gostev](https://www.linkedin.com/in/peter-gostev/)  
- **o1-pro**  

*(This README was generated by **o1-pro**.)*

---

## 9. License (MIT)

```
MIT License

Copyright (c) 2023 Peter Gostev and o1-pro

Permission is hereby granted, free of charge, to any person obtaining a copy of this
software and associated documentation files (the "Software"), to deal in the Software
without restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons
to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or
substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
```

---

Enjoy exploring how large language models respond under risk! If you have questions or improvements, feel free to open an issue or pull request.