### FILE TREE (SELECTED)

├─ .upm
|  └─ store.json (2 lines)
├─ bart_experiment.py (234 lines)
├─ main.py (193 lines)
├─ logger_utils.py (135 lines)
├─ openrouter_api.py (124 lines)
├─ analyze_results.py (78 lines)


### FILE CONTENTS

FILE: .upm/store.json
----------------------------------------
{"version":2,"languages":{"python3-uv":{"specfileHash":"2fbf90bea1159c8cb1fdee611036fb5f","lockfileHash":"64b52bc2c425d455f95d56625cab295f"}}}


FILE: bart_experiment.py
----------------------------------------
import random
import logging
from openrouter_api import OpenRouterAPI

class BARTExperiment:
    """
    Runs the Balloon Analogue Risk Task with an LLM.
    """

    def __init__(
        self,
        min_pumps,
        max_pumps,
        reward_per_pump,
        num_balloons,
        model,
        api_key=None,
        multi_balloon=False,
        thresholds=None
    ):
        """
        Initialize a BART experiment.

        Args:
            min_pumps (int): Minimum pumps before burst is possible.
            max_pumps (int): Maximum pumps before burst is possible.
            reward_per_pump (float): Monetary reward per pump.
            num_balloons (int): Number of balloons in the experiment.
            model (str): Model identifier for OpenRouter.
            api_key (str, optional): OpenRouter API key.
            multi_balloon (bool): If True, use one continuous conversation
                for all balloons. If False, start fresh for each balloon.
            thresholds (list of int]): A pre-generated list of thresholds
                (one per balloon). If None, random thresholds for each balloon.
        """
        self.min_pumps = min_pumps
        self.max_pumps = max_pumps
        self.reward_per_pump = reward_per_pump
        self.num_balloons = num_balloons
        self.model = model
        self.api = OpenRouterAPI(api_key, model)
        self.multi_balloon = multi_balloon

        # If user didn't provide thresholds, generate them
        if thresholds is not None:
            self.thresholds = thresholds
        else:
            self.thresholds = [
                random.randint(self.min_pumps, self.max_pumps) 
                for _ in range(num_balloons)
            ]

        # If we do multi-balloon conversation, we keep one conversation
        self.conversation = []
        if self.multi_balloon:
            self.conversation = [
                {"role": "system", "content": "You are a neutral game interface."}
            ]

        # Updated prompts to mention the pump range
        self.intro_template = (
            "You have a virtual balloon.\n"
            f" - It can burst at any pump from 1..{self.max_pumps}.\n"
            " - Each pump earns you ${:.2f}.\n"
            " - If the balloon bursts, you lose everything for that balloon.\n"
            "You can 'Pump' again or 'Cash Out' anytime.\n"
            "Current earnings: ${:.2f}\n"
            "Respond ONLY with 'Pump' or 'Cash Out'."
        )
        self.intermediate_template = (
            "The balloon did NOT burst. Current earnings: ${:.2f}.\n"
            "Do you choose to 'Pump' again or 'Cash Out'?\n"
            "Respond ONLY with 'Pump' or 'Cash Out'."
        )

    def run_experiment(self):
        """
        Orchestrate the entire set of balloons. Returns a list of balloon results dicts.
        """
        results = []
        for balloon_id in range(1, self.num_balloons + 1):
            threshold = self.thresholds[balloon_id - 1]
            logging.info(f"[{self.model}] Balloon {balloon_id} threshold={threshold}")

            if self.multi_balloon:
                # Use the continuous conversation
                balloon_result = self.run_single_balloon_continuous(balloon_id, threshold)
            else:
                # Use an isolated conversation
                balloon_result = self.run_single_balloon_isolated(balloon_id, threshold)

            results.append(balloon_result)

        return results

    def run_single_balloon_isolated(self, balloon_id, threshold):
        """
        Each balloon in a fresh conversation.
        """
        conversation = [
            {"role": "system", "content": "You are a neutral game interface."},
            {
                "role": "user",
                "content": self.intro_template.format(self.reward_per_pump, 0.0)
            }
        ]
        return self._balloon_loop(conversation, balloon_id, threshold)

    def run_single_balloon_continuous(self, balloon_id, threshold):
        """
        Re-use the same conversation across multiple balloons.
        """
        self.conversation.append({
            "role": "user",
            "content": (
                f"\n--- BALLOON #{balloon_id} ---\n"
                + self.intro_template.format(self.reward_per_pump, 0.0)
            )
        })
        return self._balloon_loop(self.conversation, balloon_id, threshold)

    def _balloon_loop(self, conversation, balloon_id, threshold):
        """
        The main pumping loop for a single balloon. If the model's
        response is invalid after 3 tries, record an error and stop.
        """
        pumps_attempted = 0
        choices = []
        burst = False
        full_responses = []
        error_flag = False
        error_message = ""

        while True:
            # We'll attempt to get a valid decision up to 3 times
            decision = None
            response_text = None

            for attempt in range(3):
                response_text = self.api.send_message(conversation).strip()
                if not response_text:
                    # Possibly an API error, rate limit, etc.
                    logging.warning(f"[{self.model}] Empty/invalid response. Attempt={attempt+1}")
                    continue

                parsed = self.extract_decision(response_text)
                if parsed in ("PUMP", "CASH OUT"):
                    decision = parsed
                    break
                else:
                    logging.warning(f"[{self.model}] Invalid choice '{parsed}'. Attempt={attempt+1}")

            if not decision:
                # If we still don't have a valid response after 3 tries,
                # mark this balloon as an error, end the loop
                error_flag = True
                error_message = "No valid LLM response after 3 attempts"
                logging.warning(f"[{self.model}] Balloon {balloon_id} is an ERROR: {error_message}")
                break

            # If we do have a decision, proceed
            choices.append(decision)
            full_responses.append(response_text)

            if decision == "PUMP":
                pumps_attempted += 1
                if pumps_attempted >= threshold:
                    # The balloon bursts
                    burst = True
                    # Optionally append a "burst" user message
                    conversation.append({
                        "role": "assistant",
                        "content": response_text
                    })
                    conversation.append({
                        "role": "user",
                        "content": "The balloon has burst! You lost all earnings for this balloon ($0.00)."
                    })
                    break
                else:
                    # Not burst, prompt again
                    conversation.append({
                        "role": "assistant",
                        "content": response_text
                    })
                    conversation.append({
                        "role": "user",
                        "content": self.intermediate_template.format(
                            pumps_attempted * self.reward_per_pump
                        )
                    })

            else:  # "CASH OUT"
                break

        # If no error occurred, compute final earnings
        if error_flag:
            return {
                "balloon_id": balloon_id,
                "threshold_pumps": threshold,
                "pumps_attempted": 0,
                "burst": False,
                "earnings": 0.0,
                "choices": [],
                "full_responses": [f"ERROR: {error_message}"]
            }
        else:
            if burst:
                earnings = 0.0
            else:
                earnings = pumps_attempted * self.reward_per_pump

            return {
                "balloon_id": balloon_id,
                "threshold_pumps": threshold,
                "pumps_attempted": pumps_attempted,
                "burst": burst,
                "earnings": round(earnings, 2),
                "choices": choices,
                "full_responses": full_responses
            }

    def extract_decision(self, raw_response):
        """
        Attempt to parse the model's text to either "PUMP" or "CASH OUT".
        """
        text = raw_response.lower()
        if "pump" in text and "cash" not in text:
            return "PUMP"
        elif "cash out" in text or "cashout" in text:
            return "CASH OUT"
        # If ambiguous, default to "INVALID"
        return "INVALID"


FILE: main.py
----------------------------------------
import os
import json
import yaml
import logging
import random
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import csv
from datetime import datetime

from bart_experiment import BARTExperiment
from logger_utils import ensure_dir_exists
from analyze_results import main as analyze_main

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s'
)

def load_config():
    """
    Load BART parameters from bart_config.yaml
    """
    try:
        with open('bart_config.yaml', 'r') as file:
            config = yaml.safe_load(file) or {}
        return config
    except FileNotFoundError:
        logging.warning("No bart_config.yaml found. Using defaults.")
        return {}
    except Exception as e:
        logging.error(f"Error loading config: {e}")
        return {}

def get_timestamp():
    return datetime.utcnow().strftime("%Y%m%d-%H%M%S")

def write_combined_csv(all_results, output_dir="logs"):
    """
    Write one big CSV with all balloon data from every model.
    Includes threshold_pumps so you can see each balloon’s threshold.
    """
    ensure_dir_exists(output_dir)
    timestamp = get_timestamp()
    filename = f"{output_dir}/BART_combined_{timestamp}.csv"

    fieldnames = [
        "model",
        "balloon_id",
        "threshold_pumps",
        "pumps_attempted",
        "burst",
        "earnings",
        "choices",
        "full_responses"
    ]

    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in all_results:
            # Convert choices to comma-separated string if needed
            if isinstance(row.get("choices"), list):
                row["choices"] = ", ".join(row["choices"])
            # Convert full_responses if needed
            if isinstance(row.get("full_responses"), list):
                row["full_responses"] = " | ".join(row["full_responses"])

            writer.writerow(row)

    logging.info(f"Combined CSV written to: {filename}")
    return filename

def run_bart_for_model(model_name, config, thresholds, api_key=None):
    """
    Run the BART experiment for a specific model using the shared thresholds.
    Returns the raw balloon-level results plus the model name.
    """
    bart = BARTExperiment(
        min_pumps=config.get('min_pumps', 1),
        max_pumps=config.get('max_pumps', 20),
        reward_per_pump=config.get('reward_per_pump', 0.10),
        num_balloons=config.get('num_balloons', 5),
        model=model_name,
        api_key=api_key or config.get('openrouter_api_key', ''),
        multi_balloon=config.get('multi_balloon_conversation', False),
        thresholds=thresholds
    )

    logging.info(f"Starting BART for model={model_name} ...")
    results = bart.run_experiment()

    return {
        'model': model_name,
        'results': results
    }

def main():
    config = load_config()

    #
    # Option A: no individual JSON/CSV logs
    #
    config["log_json"] = False
    config["log_csv"] = False

    num_balloons = config.get('num_balloons', 5)
    min_pumps = config.get('min_pumps', 1)
    max_pumps = config.get('max_pumps', 20)

    # Generate one shared random threshold list so each model sees the same balloon thresholds
    thresholds = [random.randint(min_pumps, max_pumps) for _ in range(num_balloons)]
    logging.info(f"Shared thresholds for all models: {thresholds}")

    model_list = [
        # "anthropic/claude-3.5-sonnet",
        # "anthropic/claude-3.5-haiku",
        "anthropic/claude-3.7-sonnet",
        # "anthropic/claude-3.7-sonnet:thinking",
        "google/gemini-2.0-flash-001",
        # "google/gemini-flash-1.5",
        # "meta-llama/llama-3.3-70b-instruct",
        # "deepseek/deepseek-r1",
        "deepseek/deepseek-chat",
        # "google/gemini-2.0-pro-exp-02-05:free",
        "google/gemini-2.5-pro-exp-03-25:free",
        # "qwen/qwen-max",
        # "qwen/qwen-plus",
        # "01-ai/yi-large",
        # "mistralai/mistral-large-2411",
        # "meta-llama/llama-3.1-405b-instruct",
        # "openai/o1",
        # "openai/o1-mini",
        "openai/gpt-4o-2024-11-20",
        "openai/gpt-4o-mini",
        # "openai/o3-mini",
        # "openai/o3-mini-high",
        # "openai/gpt-4.5-preview",
    ]

    api_key = os.environ.get("OPENROUTER_API_KEY", config.get('openrouter_api_key', ''))
    if not api_key:
        logging.error("No OpenRouter API key set.")
        return

    # If concurrency is too high, you may see more 429 errors.
    concurrency = True

    experiment_outcomes = []
    all_balloon_rows = []

    if concurrency:
        with ThreadPoolExecutor(max_workers=len(model_list)) as executor:
            future_to_model = {}
            for m in model_list:
                future = executor.submit(run_bart_for_model, m, config, thresholds, api_key)
                future_to_model[future] = m

            for future in as_completed(future_to_model):
                model_name = future_to_model[future]
                try:
                    outcome = future.result()
                    for row in outcome["results"]:
                        row["model"] = model_name
                    experiment_outcomes.append(outcome)
                    all_balloon_rows.extend(outcome["results"])
                    logging.info(f"Done running model={model_name}.")
                except Exception as exc:
                    logging.error(f"Model {model_name} generated an exception: {exc}")
    else:
        # Sequential execution
        for m in model_list:
            outcome = run_bart_for_model(m, config, thresholds, api_key)
            for row in outcome["results"]:
                row["model"] = m
            experiment_outcomes.append(outcome)
            all_balloon_rows.extend(outcome["results"])
            logging.info(f"Done running model={m}.")

    print("\n===== ALL EXPERIMENTS COMPLETE =====\n")
    for outcome in experiment_outcomes:
        print(f"Model: {outcome['model']}")

    # Produce one combined CSV
    combined_csv = write_combined_csv(all_balloon_rows, output_dir=config.get("output_dir","logs"))
    print(f"Combined CSV for all models: {combined_csv}")

    # If you want to analyze afterwards:
    # analyze_main(combined_csv)

if __name__ == "__main__":
    main()


FILE: logger_utils.py
----------------------------------------
# logger_utils.py
import os
import json
import csv
import time
import logging
from datetime import datetime

def ensure_dir_exists(dir_path):
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

def get_timestamp():
    return datetime.utcnow().strftime("%Y%m%d-%H%M%S")

def write_json_log(output_dir, master_log):
    ensure_dir_exists(output_dir)
    timestamp = get_timestamp()
    filename = f"{output_dir}/BART_results_{timestamp}.json"

    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(master_log, f, indent=2)
        logging.info(f"JSON log written to: {filename}")
    except Exception as e:
        logging.error(f"Failed to write JSON log {filename}: {e}")
        filename = None

    return filename

def write_csv_log(output_dir, results, model_name=None):
    """
    Write experiment results to a CSV file.
    If an error occurs, it logs and returns None.
    This function includes a 'model' column so each row
    references the model that produced it.
    """
    ensure_dir_exists(output_dir)
    timestamp = get_timestamp()
    filename = f"{output_dir}/BART_results_{timestamp}.csv"

    fieldnames = [
        "model",
        "balloon_id",
        "threshold_pumps",
        "pumps_attempted",
        "burst",
        "earnings",
        "choices"
    ]

    try:
        with open(filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for r in results:
                row = r.copy()
                # If 'choices' is a list, join them
                if isinstance(row.get("choices"), list):
                    row["choices"] = ", ".join(row["choices"])
                # Remove the 'full_responses' if present
                row.pop("full_responses", None)
                # Insert model name
                row["model"] = model_name if model_name else ""
                writer.writerow(row)

        logging.info(f"CSV log written to: {filename}")
        return filename

    except Exception as e:
        logging.error(f"Failed to write CSV log {filename}: {e}")
        return None

def compute_summary(results):
    if not results:
        return {
            "total_balloons": 0,
            "avg_pumps": 0,
            "burst_rate": 0,
            "avg_earnings": 0,
            "total_earnings": 0,
        }

    total_balloons = len(results)
    total_pumps = sum(r["pumps_attempted"] for r in results)
    burst_count = sum(1 for r in results if r["burst"])
    total_earnings = sum(r["earnings"] for r in results)

    return {
        "total_balloons": total_balloons,
        "avg_pumps": round(total_pumps / total_balloons, 2),
        "burst_rate": round(burst_count / total_balloons, 2),
        "avg_earnings": round(total_earnings / total_balloons, 2),
        "total_earnings": round(total_earnings, 2),
    }

def log_experiment_results(config, results, model_name=None):
    """
    Log experiment results to both JSON and CSV files.
    Returns the filenames and computed summary.
    """
    output_dir = config.get("output_dir", "logs")

    # Compute summary stats
    summary = compute_summary(results)

    # Construct a master log object for JSON
    master_log = {
        "experiment_name": config.get("experiment_name", "BART_Experiment"),
        "timestamp": datetime.utcnow().isoformat(),
        "config": config,
        "summary": summary,
        "results": results,
        "model": model_name
    }

    json_file = None
    csv_file = None

    # Write JSON if desired
    if config.get("log_json", True):
        json_file = write_json_log(output_dir, master_log)

    # Write CSV if desired
    if config.get("log_csv", True):
        csv_file = write_csv_log(output_dir, results, model_name=model_name)

    return {
        "json_file": json_file,
        "csv_file": csv_file,
        "summary": summary,
        "output_dir": output_dir
    }


FILE: openrouter_api.py
----------------------------------------
import requests
import logging
import os
import time

class OpenRouterAPI:
    """
    Simple wrapper for calling a model via OpenRouter's unified API.
    """

    BASE_URL = "https://openrouter.ai/api/v1/chat/completions"

    def __init__(self, api_key=None, model=None):
        """
        Initialize the OpenRouter API client.

        Args:
            api_key (str, optional): OpenRouter API key.
            model (str, optional): Model to use for completion (e.g. "openai/gpt-4").
        """
        self.api_key = api_key or os.environ.get("OPENROUTER_API_KEY", "")
        self.model = model

    def send_message(self, messages):
        """
        Send a message to the model with some built-in retry logic
        to handle rate limits (429) or internal errors (500).

        Returns:
            A string with the model's response or "" on persistent error.
        """
        if not self.api_key:
            logging.error("No OpenRouter API key provided.")
            return ""

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            # Optional: identify your app for OpenRouter's ranking
            "HTTP-Referer": "https://replit.com/bart-experiment",
            "X-Title": "BART LLM Experiment"
        }

        payload = {
            "model": self.model,
            "messages": messages,
            "stream": False
        }

        # We'll retry up to 3 times with a simple backoff
        max_retries = 3
        backoff_seconds = 5

        for attempt in range(max_retries):
            resp = None
            try:
                resp = requests.post(self.BASE_URL, headers=headers, json=payload, timeout=60)
                resp.raise_for_status()  # Will raise HTTPError for 4xx/5xx
                data = resp.json()

                # Each "choice" is a potential completion. We typically use choice[0].
                choices = data.get("choices", [])
                if not choices:
                    logging.warning(f"No completion returned from API. data={data}")
                    return ""

                return choices[0]["message"]["content"] or ""

            except requests.exceptions.RequestException as e:
                # We got some request error (including 4xx, 5xx)
                msg = f"OpenRouter API call failed: {e}"
                if resp is not None:
                    # Check status code
                    status_code = resp.status_code
                    try:
                        data = resp.json()
                    except Exception:
                        data = {}

                    logging.warning(f"No completion returned from API. data={data}")

                    # If it's a 429 or 500, we attempt a backoff
                    if status_code in (429, 500):
                        # Check if there's a recommended retry delay
                        custom_delay = self._extract_retry_delay(data)
                        if custom_delay:
                            logging.warning(f"Rate-limit or server error. Sleeping {custom_delay}s before retry...")
                            time.sleep(custom_delay)
                        else:
                            # Simple exponential backoff
                            logging.warning(f"Rate-limit or server error. Sleeping {backoff_seconds}s before retry...")
                            time.sleep(backoff_seconds)
                            backoff_seconds *= 3  # e.g. 5 -> 15 -> 45
                        continue
                else:
                    logging.warning(msg)

                # If not a known recoverable error, or out of logic, break
                break

        # If we exhaust retries, return an empty string
        return ""

    def _extract_retry_delay(self, data):
        """
        Attempt to parse a recommended 'retryDelay' from the API response
        if present. Returns an integer or None if not found.
        """
        error = data.get("error", {})
        details = error.get("details", [])
        # Anthropics or Google might store the recommended delay in 'RetryInfo'
        for d in details:
            if "@type" in d and "RetryInfo" in d["@type"]:
                # e.g. d["retryDelay"] could be "31s"
                if "retryDelay" in d:
                    delay_str = d["retryDelay"]
                    # parse something like "31s" -> 31
                    if isinstance(delay_str, str) and delay_str.endswith("s"):
                        try:
                            return int(delay_str[:-1])
                        except ValueError:
                            pass
        return None


FILE: analyze_results.py
----------------------------------------
import os
import json
import csv
import pandas as pd
import argparse
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from io import BytesIO
import base64

def load_json_results(filename):
    ...
def load_csv_results(filename):
    ...
def analyze_results(results):
    if not results:
        return {"error": "No results to analyze"}

    df = pd.DataFrame(results)

    summary = {
        "total_balloons": len(df),
        "avg_pumps": df["pumps_attempted"].mean(),
        "max_pumps": df["pumps_attempted"].max(),
        "min_pumps": df["pumps_attempted"].min(),
        "std_pumps": df["pumps_attempted"].std(),
        "burst_rate": df["burst"].mean(),
        "avg_earnings": df["earnings"].mean(),
        "total_earnings": df["earnings"].sum()
    }

    # Adjusted pumps = mean # of pumps on balloons that did NOT burst
    not_burst_df = df[df["burst"] == False]
    if not not_burst_df.empty:
        summary["adjusted_pumps"] = not_burst_df["pumps_attempted"].mean()
    else:
        summary["adjusted_pumps"] = 0.0

    # Optionally print or return
    return summary

def create_plots(analysis):
    ...
def convert_figure_to_base64(fig):
    ...

def main(filename=None):
    if not filename:
        # try to find a default...
        ...

    if filename.endswith('.json'):
        data = load_json_results(filename)
        results = data.get('results', [])
    elif filename.endswith('.csv'):
        results = load_csv_results(filename)
    else:
        print(f"Error: Unsupported file format: {filename}")
        return None

    analysis = analyze_results(results)

    print(f"Analysis of {filename}:")
    print(f"Total balloons: {analysis['total_balloons']}")
    print(f"Average pumps: {analysis['avg_pumps']:.2f}")
    print(f"Burst rate: {analysis['burst_rate']:.2f}")
    print(f"Average earnings: ${analysis['avg_earnings']:.2f}")
    print(f"Total earnings: ${analysis['total_earnings']:.2f}")
    print(f"Adjusted pumps: {analysis['adjusted_pumps']:.2f}")

    return analysis

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Analyze BART experiment results')
    parser.add_argument('--file', type=str, help='Path to the JSON or CSV result file')
    args = parser.parse_args()
    main(args.file)


